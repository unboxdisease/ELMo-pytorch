{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Formed and saved. The length of dictionary is-:  9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bi_RNN(\n",
       "  (lstm): LSTM(50, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=200, out_features=9773, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from dataset import Dataset_seq,build_vocab\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import time\n",
    "from model import Bi_RNN\n",
    "\n",
    "train_path = './Dataset/yelp-subset.train.csv'\n",
    "word2id_ts,id2word_ts = build_vocab(train_path)\n",
    "model = Bi_RNN(50, 100, 100, 9773, 2)\n",
    "model.load_state_dict(torch.load('./models/model_20.pt'))\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from dataset import Dataset_seq,Dataset_class\n",
    "yelp_train = Dataset_seq(word2id_ts,id2word_ts, train_path)\n",
    "word2rep = yelp_train.word2representation\n",
    "# def csv_to_dataframe(path):\n",
    "df = pd.read_csv(train_path, sep=',', header=None)\n",
    "df.columns = ['label', 'text']\n",
    "df = df[1:]\n",
    "X = []\n",
    "Y = []\n",
    "for idx, row in enumerate(df.text):\n",
    "    sent = gensim.utils.simple_preprocess(df.iloc[idx].text,min_len=1)\n",
    "    sent = [word if word in yelp_train.word2id else '<unk>' for word in sent]\n",
    "    X.append([word2rep[w] for w in sent])\n",
    "    Y.append(df.iloc[idx].label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.FloatTensor([X[1]]).to('cuda')\n",
    "out,lstm = model(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 214, 200])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'classifier' from 'model' (/home/kushal/Kushal/7sem/ANLP/ELMo-pytorch/model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classifier\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'classifier' from 'model' (/home/kushal/Kushal/7sem/ANLP/ELMo-pytorch/model.py)"
     ]
    }
   ],
   "source": [
    "from model import classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1306,  0.1368, -0.0943, -0.0820, -0.1173]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model2 = classifier(200,100,1)\n",
    "model2.to('cuda')\n",
    "model2.eval()\n",
    "out = model2(lstm)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.init(project=\"ELMo\", entity=\"kushaljain\")\n",
    "lr = 0.0003\n",
    "epochs = 50\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = model.float()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "error = {\"train\": [], \"val\": []}\n",
    "accuracy = {\"train\" : [], \"val\" : []}\n",
    "perplexity = {\"train\": [], \"val\": []}\n",
    "times = {\"train\": [], \"val\": []}\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.003,\n",
    "  \"epochs\": 100,\n",
    "  \"batch_size\": 100\n",
    "}\n",
    "print(device)\n",
    "\n",
    "import sys\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time()\n",
    "    print(\"starting Epoch : \" + str(epoch + 1))\n",
    "\n",
    "    train_samples = 0\n",
    "    val_samples = 0\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    train_accuracy = 0\n",
    "    t1 = time.time()\n",
    "    model.train()\n",
    "    for input_vector, label in train_dl:\n",
    "        \n",
    "\n",
    "        # add the input vector and label to the gpu\n",
    "        input_vector = input_vector.float()\n",
    "        input_vector = input_vector.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits,_ = model(input_vector)\n",
    "#         print(\"shape of the logits : {0}\",format(logits.shape))\n",
    "#         print(\"shape of the label : {0}\",format(label.shape))       \n",
    "        logits = logits.view(logits.shape[1]* logits.shape[0], logits.shape[2])\n",
    "        label = label.view(-1)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(logits, label)\n",
    "\n",
    "        # set the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # back.prop\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predictions = logits.argmax(dim=1)\n",
    "\n",
    "        # update accuracy\n",
    "        train_accuracy += (predictions == label).sum()  \n",
    "        train_samples += logits.shape[0]\n",
    "#         print(train_accuracy)\n",
    "#         print(train_samples)\n",
    "        print(\"Progress : {0} \".format((train_samples/2000) * 100 / len(train_dl)),end='\\r')\n",
    "        \n",
    "    t2 = time.time()\n",
    "    print(\"Time taken to run training for epoch {0} : {1} \".format(\n",
    "        epoch, t2 - t1))\n",
    "    t3 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    for input_vector, label in val_dl:\n",
    "\n",
    "        # add the input vector and label to the gpu\n",
    "        input_vector = input_vector.float()\n",
    "        input_vector = input_vector.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits,_ = model(input_vector)\n",
    "        logits = logits.view(logits.shape[1]* logits.shape[0], logits.shape[2])\n",
    "        label = label.view(-1)\n",
    "        \n",
    "\n",
    "        \n",
    "        # compute loss\n",
    "        loss = criterion(logits, label)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        \n",
    "        # update accuracy\n",
    "        val_accuracy += (predictions == label).sum()\n",
    "\n",
    "        val_samples += logits.shape[0]\n",
    "        \n",
    "        print(\"Progress : {0} \".format((val_samples/2000) * 100 / len(val_dl)),end='\\r')\n",
    "        \n",
    "\n",
    "    t4 = time.time()\n",
    "    train_perplexity = np.exp(train_loss/len(train_dl))\n",
    "    val_perplexity = np.exp(val_loss/len(val_dl))\n",
    "    train_accuracy = train_accuracy / train_samples\n",
    "    val_accuracy = val_accuracy / val_samples\n",
    "    print(\"Time taken to run training for epoch {0} : {1} \".format(\n",
    "        epoch, t4 - t3))\n",
    "    print(\"Total Time for epoch {0} is {1}\".format(epoch+1, t4 - t1))\n",
    "    print(\"Training Loss for epoch {0} : {1} \".format(epoch + 1, train_loss))\n",
    "    print(\"Training Accuracy for epoch {0} : {1}\".format(\n",
    "        epoch + 1, train_accuracy))\n",
    "\n",
    "    print(\"Val Loss for epoch {0} : {1} \".format(epoch + 1, val_loss))\n",
    "    print(\"Val Accuracy for epoch {0} : {1}\".format(epoch + 1, val_accuracy))\n",
    "    print(\"Train perplexity for epoch {0} : {1}\".format(\n",
    "        epoch + 1, train_perplexity))\n",
    "    print(\"Val perplexity for epoch {0} : {1}\".format(\n",
    "        epoch + 1, val_perplexity))\n",
    "    error['train'].append(train_loss)\n",
    "    error['val'].append(val_loss)\n",
    "    accuracy['train'].append(train_accuracy)\n",
    "    accuracy['val'].append(val_accuracy)\n",
    "    times['train'].append(t2 - t1)\n",
    "    times['val'].append(t4-t3)\n",
    "    perplexity['train'].append(train_perplexity)\n",
    "    perplexity['val'].append(val_perplexity)\n",
    "\n",
    "    \n",
    "    wandb.log({\n",
    "        \"Training loss\": train_loss,\n",
    "        \"Validation loss\": val_loss,\n",
    "        \"Train accuracy\" : train_accuracy,\n",
    "        \"Validation accuracy\" : val_accuracy\n",
    "              })\n",
    "    \n",
    "    # save the model\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(\"Saving the model \")\n",
    "        torch.save(model.state_dict(),'./models/model_{0}.pt'.format(epoch + 1))\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdd9074d09183e8bc0025300cef7a83eb88924cf0a158e90afa6b5f04cbbd876"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
